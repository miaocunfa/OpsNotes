---
title: "容器化解决方案"
date: "2020-06-03"
categories:
    - "技术"
tags:
    - "Kubernetes"
    - "容器化"
    - "解决方案"
toc: false
indent: false
original: true
---

## 更新记录

| 时间       | 内容                                                                                                                            |
| ---------- | ------------------------------------------------------------------------------------------------------------------------------- |
| 2020-06-03 | 初稿                                                                                                                            |
| 2020-07-23 | 持续不断的寻找云原生最优解</br>1、移除 Gitlab QA 部分，独立为一篇 Blog</br>2、移除 Deployment YAML部分，更新为自动生成脚本</br> |
| 2020-07-24 | 1、日志系统从EFK迁移为Loki</br>2、增加Helm包管理部分                                                                            |

## 一、测试环境

### 1.1、前置条件

进行系统内核升级 3.10 --> ~~4.0+~~ 5.7.6

### 1.2、硬件资源

``` zsh
# 查看内存资源
ansible 23 -m shell -a "free -h| grep Mem | awk '{print $2}'"

# 查看CPU资源
➜  ansible 23 -m shell -a "cat /proc/cpuinfo | grep "processor.*:" | wc -l"
```

### 1.3、规划

Kubernetes版本：1.16.10

| 节点            | 服务                        | 配置   |
| --------------- | --------------------------- | ------ |
| 192.168.100.231 | K8s Node                    | 4C 8G  |
| 192.168.100.232 | K8s Node                    | 4C 8G  |
| 192.168.100.237 | K8s Node                    | 4C 8G  |
| 192.168.100.233 | Harbor、Prometheus、grafana | 16C 8G |
| 192.168.100.235 | ~~ELK Cluster~~ Loki        | 8C 8G  |
| 192.168.100.236 | K8s Master、Ansible         | 4C 4G  |
| 192.168.100.253 | Ceph Server                 |        |

### 1.4、私有镜像库

搭建Harbor作为私有镜像库

#### 1.4.1、Harbor Server Info

``` info
    IP:   192.168.100.233
    user: admin
    pass: Harbor123
```

#### 1.4.2、Harbor Server 操作

``` zsh
➜  cd /root/harbor

# 启动 Harbor
➜  docker-compose up
➜  docker-compose ps
      Name                     Command                  State       Ports
------------------------------------------------------------------------------------------------------------------------------------
chartmuseum         /docker-entrypoint.sh            Up (healthy)   9999/tcp
clair               /docker-entrypoint.sh            Up (healthy)   6060/tcp, 6061/tcp
harbor-core         /harbor/start.sh                 Up (healthy)
harbor-db           /entrypoint.sh postgres          Up (healthy)   5432/tcp
harbor-jobservice   /harbor/start.sh                 Up
harbor-log          /bin/sh -c /usr/local/bin/ ...   Up (healthy)   127.0.0.1:1514->10514/tcp
harbor-portal       nginx -g daemon off;             Up (healthy)   80/tcp
nginx               nginx -g daemon off;             Up (healthy)   0.0.0.0:443->443/tcp, 0.0.0.0:4443->4443/tcp, 0.0.0.0:80->80/tcp
notary-server       /bin/server-start.sh             Up
notary-signer       /bin/signer-start.sh             Up
redis               docker-entrypoint.sh redis ...   Up             6379/tcp
registry            /entrypoint.sh /etc/regist ...   Up (healthy)   0.0.0.0:5000->5000/tcp
registryctl         /harbor/start.sh                 Up (healthy)

# 停止 Harbor
➜  docker-compose down
```

#### 1.4.3、目标

1、完成私有镜像库的搭建  
2、完成应用镜像化  

### 1.5、分布式存储

搭建Ceph分布式存储为K8s集群提供存储服务

Ceph的部署文档：  
1、[Ceph存储集群](https://github.com/miaocunfa/OpsNotes/blob/master/Storage/Ceph/Ceph%E5%AD%98%E5%82%A8%E9%9B%86%E7%BE%A4.md)  
2、[Ceph对象存储](https://github.com/miaocunfa/OpsNotes/blob/master/Storage/Ceph/Ceph%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8.md)  
3、[Ceph错误汇总](https://github.com/miaocunfa/OpsNotes/blob/master/Storage/Ceph/Ceph%E9%94%99%E8%AF%AF%E6%B1%87%E6%80%BB.md)  
4、[Kubernetes使用Ceph生成动态PV](https://github.com/miaocunfa/OpsNotes/blob/master/Kubernetes-stack/Ceph/Kubernetes%E4%BD%BF%E7%94%A8Ceph%E7%94%9F%E6%88%90%E5%8A%A8%E6%80%81PV.md)  

#### 1.5.1、Ceph Info

``` info
    IP: 192.168.100.253
```

#### 1.5.2、目标

1、完成分布式存储的搭建  
2、提供ceph的对象存储  
3、提供ceph的rbd存储  
4、使用ceph-rbd实现kubernetes集群pv动态供给  

### 1.6、日志监控系统

~~使用EFK技术栈来实现日志监控系统~~

经过尝试改用 Loki后，我只能说一个字，香！

#### 1.6.1、Loki - 日志新贵

Loki的部署文档：  
1、[使用Loki进行日志监控和报警](https://github.com/miaocunfa/OpsNotes/blob/master/Kubernetes-stack/Loki/%E4%BD%BF%E7%94%A8Loki%E8%BF%9B%E8%A1%8C%E6%97%A5%E5%BF%97%E7%9B%91%E6%8E%A7%E5%92%8C%E6%8A%A5%E8%AD%A6.md)  
2、[非Kubernetes环境下部署Loki](https://github.com/miaocunfa/OpsNotes/blob/master/Monitor/%E9%9D%9EKubernetes%E7%8E%AF%E5%A2%83%E4%B8%8B%E9%83%A8%E7%BD%B2Loki.md)  

##### 1.6.1.1、Loki 优缺点

- 不对日志进行全文本索引。通过存储压缩的，非结构化的日志以及仅索引元数据，Loki更加易于操作且运行成本更低。
- 使用与Prometheus相同的标签对日志流进行索引和分组，从而使您能够使用与Prometheus相同的标签在指标和日志之间无缝切换。
- 特别适合存储Kubernetes Pod日志。诸如Pod标签之类的元数据会自动被抓取并建立索引。
- 在Grafana中具有本机支持（需要Grafana v6.0）。可以在查看指标数据和日志的时候不用在Grafana和Kibana之间来回切换。

##### 1.6.1.2、Loki 操作

``` zsh
# Loki
➜  cd /opt/loki
➜  nohup ./loki-linux-amd64 -config.file=./loki-local-config.yaml &

# promtail
➜  cd /opt/promtail
➜  nohup ./promtail-linux-amd64 -config.file=./promtail-local-config.yaml &

# grafana
➜  systemctl start grafana-server
```

##### 1.6.1.3、Loki 使用目标

1、完成系统搭建  
2、实现k8s集群内应用日志的收集、展示  
3、使用ansible playbook实现整个Loki系统的重启  

#### 1.6.2、~~EFK~~ - 已弃用

##### 1.6.2.1、~~EFK Info~~

``` info
    elasticsearch: 192.168.100.235:9200
    kibana:        192.168.100.235:5601
    fluentd：      Node节点启用的日志收集器
```

##### 1.6.2.2、~~EFK 操作~~

``` zsh
# elasticsearch Server
➜  su - elasticsearch
➜  cd /opt/elasticsearch-7.1.1/bin
➜  ./elasticsearch -d

# kibana Server
➜  cd /opt/kibana-7.1.1-linux-x86_64/bin
➜  nohup ./kibana serve &

# fluentd
# 在k8s集群中启动fluentd的ds副本即可
```

##### 1.6.2.3、~~EFK 使用目标~~

1、完成系统搭建  
2、实现k8s集群内应用日志的收集、展示  
3、使用ansible playbook实现整个ELK系统的重启  

### 1.7、监控告警系统

使用Prometheus技术栈实现监控告警系统

#### 1.7.1、Prometheus Info

``` info
    Prometheus Server: 192.168.100.233:9090
    grafana:           192.168.100.233:3000
    alertmanager:      192.168.100.233
    node_export:       K8s-Node   9100
                       非K8s-Node 10091
```

#### 1.7.2、Prometheus 操作

``` zsh
# Prometheus Server
➜  cd /usr/local/prometheus-2.13.1.linux-amd64
➜  nohup ./prometheus --storage.tsdb.retention=180d --web.enable-admin-api &

# grafana Server
➜  cd /usr/local/grafana-6.4.4/bin
➜  nohup ./grafana-server &

# alertmanager Server
➜  cd /usr/local/alertmanager-0.19.0.linux-amd64
➜  nohup ./alertmanager &

# Node_exporter Server
# 非k8s节点，监听10091端口
➜ cd /opt/node_exporter-0.18.1.linux-amd64
➜ nohup ./node_exporter --web.listen-address=":10091" &

# k8s节点，监听9100端口
# 在k8s集群中启动node_exporter的ds副本即可
```

#### 1.7.1、目标

1、完成系统搭建  
2、使用prometheus实现对整个测试环境的指标监控、告警  
3、使用ansible playbook实现整个监控系统的重启

- node_exporter服务启动
- prometheus服务启动
- grafana服务启动

### 1.8、Helm

Helm 是 Kubernetes 的包管理器。包管理器类似于我们在 Ubuntu 中使用的 apt、Centos中使用的 yum 或者 Python 中的 pip 一样，能快速查找、下载和安装软件包。~~Helm 由客户端组件 helm 和服务端组件 Tiller 组成~~ Helm V3 经过我的使用不配置 Tiller 也能正常使用, 能够将一组K8S资源打包统一管理, 是查找、共享和使用为Kubernetes构建的软件的最佳方式。

Helm 使用文档：  
1、[Kubernetes部署工具Helm之常用操作(一)](https://github.com/miaocunfa/OpsNotes/blob/master/Kubernetes-stack/Helm/Kubernetes%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7Helm%E4%B9%8B%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C(%E4%B8%80).md)  

## 二、CI/CD

### 1.1、Jenkins

环境

``` txt
    IP: 192.168.100.221
    Path: /var/lib/jenkins
```

启动 Jenkins 服务

``` zsh
➜ systemctl start jenkins
```

### 1.2、gitlab CI

未完待续

### 1.3、TEKTON

听说很好用，还没有具体了解

### 1.4、Argo

CNCF 孵化项目，应该很好用，还没有深入了解，等了解后会更新。

## 三、应用容器化

### 3.1、Dockerfile

``` dockerfile
FROM 192.168.100.233/library/amazoncorretto:8.0
MAINTAINER Aihangxunxi<www.aihangxunxi.com>

# Add Maven dependencies (not shaded into the artifact; Docker-cached)
#ADD target/lib           /usr/share/myservice/lib
# Add the service itself
ARG JAR_FILE
ARG ARTIFACTID
ARG COPY_DIR
COPY $COPY_DIR /opt/aihangxunxi
ADD $JAR_FILE /opt/aihangxunxi/lib/${ARTIFACTID}.jar
ENV APP_ROOT=/opt/aihangxunxi APP_NAME=$ARTIFACTID
EXPOSE 8801
ENTRYPOINT ["/bin/bash", "/opt/aihangxunxi/bin/start.sh", "info-ad-service.jar"]
#CMD ["/bin/sh","-c","java -jar ${APP_ROOT}/lib/${APP_NAME}.jar > ${APP_ROOT}/logs/${APP_NAME}.log 2>&1 &"]
```

### 3.2、Deploy yaml

考虑到以后微服务越来越多，如果每次更新微服务都需要修改每一个Deployment YAML的话，工作量会非常巨大。

所以特意花了一点时间研究出了自动生成YAML，我用python做了三版自动生成脚本:  
1、[替换版](https://github.com/miaocunfa/OpsNotes/blob/master/python/Auto-Create-K8S-YAML/replace/auto_create_deploy_yaml.py)  
2、[YAML转JSON版](https://github.com/miaocunfa/OpsNotes/blob/master/Kubernetes-stack/Application/templating-kubernetes-yaml.py)  
3、[模板渲染版](https://github.com/miaocunfa/OpsNotes/blob/master/Kubernetes-stack/Application/templating-k8s-with-jinja2.py)  

为什么更新：  
1、在第一版替换版考虑到，只靠替换无法生成数组那种形式的内容，替换给你留的位置只有一个，如果你想更新多个内容就无法实现了  
2、所以进入了第二版的更新，将YAML模板读取成为JSON，根据代码修改好所有内容后，再转为JSON，这一版更新将上一版遗留的无法更新多个内容解决掉了，同时通过代码来控制内容带来的结果就是，代码量巨大，每次增加一个新属性更新起来巨费劲，代码可读性、可维护性差！  
3、柳暗花明又一村，在这个时候了解到了模板渲染jinja2，这个有点像GO模板也有点像HELM，而且上述所有功能都能实现，使用模板渲染的好处就是代码可读性和可维护性都上来了。

思考：  
1、也许在不远的未来我还会对这一部分进行更新，在我研究HELM的时候，我就发现可以创建自己的Chart，我还没有深入研究，但我感觉应该比我所写的自动生成脚本更完善。  

## 四、生产环境

### 4.1、前置条件

生产环境经典网络切换为VPC网络

### 4.2、节点规划

## 五、常见问题
